{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**FRENCH TO ENGLISH TRANSLATOR**"
      ],
      "metadata": {
        "id": "G3lDLfQJQaMp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import Libraries**"
      ],
      "metadata": {
        "id": "56qsgI6DPXNL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import MarianMTModel, MarianTokenizer\n"
      ],
      "metadata": {
        "id": "Aqs2O4WiDjg4"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Model and Tokenizer**"
      ],
      "metadata": {
        "id": "a8Y6yV0pPnS-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"Helsinki-NLP/opus-mt-en-fr\"\n",
        "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
        "model =MarianMTModel.from_pretrained(model_name)\n",
        "print(model)\n"
      ],
      "metadata": {
        "id": "iGFKjplsPg0q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fae8d18d-9c2d-432d-880d-8cb4a7ce31b2"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/marian/tokenization_marian.py:197: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MarianMTModel(\n",
            "  (model): MarianModel(\n",
            "    (shared): Embedding(59514, 512, padding_idx=59513)\n",
            "    (encoder): MarianEncoder(\n",
            "      (embed_tokens): Embedding(59514, 512, padding_idx=59513)\n",
            "      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
            "      (layers): ModuleList(\n",
            "        (0-5): 6 x MarianEncoderLayer(\n",
            "          (self_attn): MarianAttention(\n",
            "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (activation_fn): SiLU()\n",
            "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (decoder): MarianDecoder(\n",
            "      (embed_tokens): Embedding(59514, 512, padding_idx=59513)\n",
            "      (embed_positions): MarianSinusoidalPositionalEmbedding(512, 512)\n",
            "      (layers): ModuleList(\n",
            "        (0-5): 6 x MarianDecoderLayer(\n",
            "          (self_attn): MarianAttention(\n",
            "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (activation_fn): SiLU()\n",
            "          (self_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (encoder_attn): MarianAttention(\n",
            "            (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "            (out_proj): Linear(in_features=512, out_features=512, bias=True)\n",
            "          )\n",
            "          (encoder_attn_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
            "          (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
            "          (final_layer_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (lm_head): Linear(in_features=512, out_features=59514, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Translation Function**"
      ],
      "metadata": {
        "id": "88ZTGQwgPweK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def translate(text):\n",
        "    inputs = tokenizer(text,return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    outputs = model.generate(**inputs, max_length=512, num_beams=4, early_stopping=True)\n",
        "    translated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return translated_text\n"
      ],
      "metadata": {
        "id": "IrOA8QdGPrv1"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Continuous User Input**"
      ],
      "metadata": {
        "id": "Aen8pns5P8Ni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    english_text = input(\"Enter the input(or 'exit' to quit): \")\n",
        "    if english_text.lower() == 'exit':\n",
        "       print(\"Exiting...\")\n",
        "       break\n",
        "    translated_text = translate(english_text)\n",
        "    print(\"French:\", translated_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AylofvClP4OV",
        "outputId": "1d0afeb3-8b19-45eb-aa41-6170fe946587"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the input(or 'exit' to quit): How are you\n",
            "French: Comment allez-vous?\n",
            "Enter the input(or 'exit' to quit): i am a student\n",
            "French: Je suis un étudiant\n",
            "Enter the input(or 'exit' to quit): artificial intelligence\n",
            "French: intelligence artificielle\n",
            "Enter the input(or 'exit' to quit): how about you\n",
            "French: Et toi?\n",
            "Enter the input(or 'exit' to quit): machine learning\n",
            "French: l'apprentissage automatique\n",
            "Enter the input(or 'exit' to quit): i am a doctor\n",
            "French: Je suis médecin.\n",
            "Enter the input(or 'exit' to quit): fish\n",
            "French: poissons\n",
            "Enter the input(or 'exit' to quit): tommorrow\n",
            "French: tommorrow\n",
            "Enter the input(or 'exit' to quit): Tomorrow\n",
            "French: Demain\n",
            "Enter the input(or 'exit' to quit): exit\n",
            "Exiting...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ENGLISH TO TAMIL TRANSLATOR**"
      ],
      "metadata": {
        "id": "_-gnPrOCQlmR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import Libraries**"
      ],
      "metadata": {
        "id": "RDnsngq-QyJZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import M2M100ForConditionalGeneration, M2M100Tokenizer"
      ],
      "metadata": {
        "id": "5ljNc0dnQvcp"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Model and Tokenizer:**"
      ],
      "metadata": {
        "id": "rRzqg8VlRWNQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"Hemanth-thunder/english-tamil-mt\"\n",
        "tokenizer = M2M100Tokenizer.from_pretrained(model_name)\n"
      ],
      "metadata": {
        "id": "PgUjNwinQC8V"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = M2M100ForConditionalGeneration.from_pretrained(model_name)\n",
        "print(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKJ_R6anm5qc",
        "outputId": "46b91082-2771-4551-ddde-ac040bdacb20"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "M2M100ForConditionalGeneration(\n",
            "  (model): M2M100Model(\n",
            "    (shared): Embedding(128112, 1024, padding_idx=1)\n",
            "    (encoder): M2M100Encoder(\n",
            "      (embed_tokens): Embedding(128112, 1024, padding_idx=1)\n",
            "      (embed_positions): M2M100SinusoidalPositionalEmbedding()\n",
            "      (layers): ModuleList(\n",
            "        (0-11): 12 x M2M100EncoderLayer(\n",
            "          (self_attn): M2M100Attention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (activation_fn): ReLU()\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "    (decoder): M2M100Decoder(\n",
            "      (embed_tokens): Embedding(128112, 1024, padding_idx=1)\n",
            "      (embed_positions): M2M100SinusoidalPositionalEmbedding()\n",
            "      (layers): ModuleList(\n",
            "        (0-11): 12 x M2M100DecoderLayer(\n",
            "          (self_attn): M2M100Attention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (activation_fn): ReLU()\n",
            "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (encoder_attn): M2M100Attention(\n",
            "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
            "          )\n",
            "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
            "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
            "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "        )\n",
            "      )\n",
            "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
            "    )\n",
            "  )\n",
            "  (lm_head): Linear(in_features=1024, out_features=128112, bias=False)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Define Translation Function:**"
      ],
      "metadata": {
        "id": "Fkxgar7ARi4g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def translate(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
        "    outputs = model.generate(**inputs, max_length=512, num_beams=5, early_stopping=True)\n",
        "    translated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "    return translated_text\n"
      ],
      "metadata": {
        "id": "nt51teMMRcuT"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " **User Input**"
      ],
      "metadata": {
        "id": "tB5J0SlMSDNm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "while True:\n",
        "    english_text = input(\"Enter the input(or 'exit' to quit): \")\n",
        "    if english_text.lower() == 'exit':\n",
        "        print(\"Exiting...\")\n",
        "        break\n",
        "    translated_text = translate(english_text)\n",
        "    print(\"Tamil:\", translated_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rl1GdkcWRmuJ",
        "outputId": "45ebb50a-fef2-4b04-fd6b-41eaf1d62362"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the input(or 'exit' to quit): How are you?\n",
            "Tamil: நீங்கள் எப்படி இருக்கிறீர்கள்?\n",
            "Enter the input(or 'exit' to quit): artificial Intelligence\n",
            "Tamil: செயற்கை நுண்ணறிவு\n",
            "Enter the input(or 'exit' to quit): I am going to home\n",
            "Tamil: நான் வீட்டுக்குப் போகிறேன்.\n",
            "Enter the input(or 'exit' to quit): book\n",
            "Tamil: புத்தகம்\n",
            "Enter the input(or 'exit' to quit): face\n",
            "Tamil: முகம்\n",
            "Enter the input(or 'exit' to quit): I will learn tomorrow\n",
            "Tamil: நாளை நான் கற்றுக் கொள்கிறேன்.\n",
            "Enter the input(or 'exit' to quit): I miss my friend\n",
            "Tamil: எனது நண்பரை நான் இழந்து விட்டேன்.\n",
            "Enter the input(or 'exit' to quit): Priyadharshini\n",
            "Tamil: ப்ரியாதர்ஷினி\n",
            "Enter the input(or 'exit' to quit): find my book\n",
            "Tamil: என் புத்தகத்தைக் காணுங்கள்.\n",
            "Enter the input(or 'exit' to quit): house\n",
            "Tamil: வீடு\n",
            "Enter the input(or 'exit' to quit): girls\n",
            "Tamil: பெண்கள்\n",
            "Enter the input(or 'exit' to quit): boys\n",
            "Tamil: ஆண்கள்\n",
            "Enter the input(or 'exit' to quit): birds\n",
            "Tamil: பறவைகள்\n",
            "Enter the input(or 'exit' to quit): exit\n",
            "Exiting...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bFZD9gr_SJwY"
      },
      "execution_count": 71,
      "outputs": []
    }
  ]
}