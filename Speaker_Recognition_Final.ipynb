{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IwoI7QF9GHD2"
      },
      "source": [
        "**Import Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install librosa resampy\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1oVeIB_ZeNo",
        "outputId": "d6dde877-4bfa-4eb5-b222-5a1b4ed81457"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.1)\n",
            "Collecting resampy\n",
            "  Downloading resampy-0.4.3-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n",
            "Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.25.2)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.3.2)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n",
            "Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.58.1)\n",
            "Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n",
            "Requirement already satisfied: pooch>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.1)\n",
            "Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3.7)\n",
            "Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.10.0)\n",
            "Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.3)\n",
            "Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.0.8)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.41.1)\n",
            "Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (4.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (24.0)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.0->librosa) (2.31.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.3.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.16.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.21)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.0->librosa) (2024.2.2)\n",
            "Installing collected packages: resampy\n",
            "Successfully installed resampy-0.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Import Libraries**"
      ],
      "metadata": {
        "id": "Y8Ibre30hEeE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import librosa\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import joblib\n",
        "from scipy.spatial.distance import cosine\n",
        "\n"
      ],
      "metadata": {
        "id": "iyKH0OFmXmgi"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function to extract features from an audio file**"
      ],
      "metadata": {
        "id": "UbCqfgfWhLCF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_features(file_path):\n",
        "    audio, sample_rate = librosa.load(file_path, sr=None)\n",
        "    mfccs = librosa.feature.mfcc(y=audio, sr=sample_rate, n_mfcc=13)\n",
        "    mfccs_mean = np.mean(mfccs.T, axis=0)\n",
        "    return mfccs_mean"
      ],
      "metadata": {
        "id": "FdTT8Cy6crmB"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Load trained audio files**"
      ],
      "metadata": {
        "id": "n0_3F5InhX7g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trained_audio_files = [\"/content/audio (2).wav\", \"/content/audio 4.wav\"]\n",
        "trained_labels = [\"speaker1\", \"speaker2\"]"
      ],
      "metadata": {
        "id": "Q4DHqqcnhUDr"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Extract features from trained audio files**"
      ],
      "metadata": {
        "id": "u1L0XPnRhfX0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trained_features = np.array([extract_features(file) for file in trained_audio_files])"
      ],
      "metadata": {
        "id": "-V-TWZ2fhdov"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "** Print the shape of trained_features**"
      ],
      "metadata": {
        "id": "yClZnxjfh2yk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of trained_features:\", trained_features.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SohuMCQThxvn",
        "outputId": "0b179153-5253-4509-9057-9101cfb3f087"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of trained_features: (2, 13)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Set a threshold for similarit**y"
      ],
      "metadata": {
        "id": "LAUUzqQQh_u8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 0.7"
      ],
      "metadata": {
        "id": "VaTAGlPjh6tG"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Function to predict speaker**"
      ],
      "metadata": {
        "id": "ZWrswiV_iG7L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_speaker(new_audio_file):\n",
        "    # Extract features from the new audio file\n",
        "    new_features = extract_features(new_audio_file)\n",
        "    print(\"Shape of new_features before scaling:\", new_features.shape)\n",
        "    # Scale the features\n",
        "    scaler = StandardScaler()\n",
        "    trained_features_scaled = scaler.fit_transform(trained_features)\n",
        "    print(\"Shape of trained_features_scaled:\", trained_features_scaled.shape)\n",
        "    new_features_scaled = scaler.transform(new_features.reshape(1, -1))\n",
        "    print(\"Shape of new_features_scaled:\", new_features_scaled.shape)\n",
        "    # Predict the speaker\n",
        "    predicted_speaker = None\n",
        "    for i, speaker_features in enumerate(trained_features_scaled):\n",
        "        similarity = 1 - cosine(new_features_scaled.flatten(), speaker_features.flatten())\n",
        "        print(\"Similarity with\", trained_labels[i], \":\", similarity)\n",
        "        if similarity > threshold:\n",
        "            predicted_speaker = trained_labels[i]\n",
        "            break\n",
        "    return predicted_speaker"
      ],
      "metadata": {
        "id": "hQDD4XhKiDyu"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Example usage**"
      ],
      "metadata": {
        "id": "17D93_YmiNik"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Path to the new audio file for prediction\n",
        "    new_audio_file = \"/content/priya.wav\"\n",
        "\n",
        "    # Predict the speaker\n",
        "    predicted_speaker = predict_speaker(new_audio_file)\n",
        "\n",
        "    if predicted_speaker is not None:\n",
        "        print(\"Predicted Speaker:\", predicted_speaker)\n",
        "    else:\n",
        "        print(\"Unknown\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4f7a_OmiKoL",
        "outputId": "8304064e-e8a7-4c64-e052-32983cf5360c"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of new_features before scaling: (13,)\n",
            "Shape of trained_features_scaled: (2, 13)\n",
            "Shape of new_features_scaled: (1, 13)\n",
            "Similarity with speaker1 : -0.3899553418159485\n",
            "Similarity with speaker2 : 0.3899553418159485\n",
            "Unknown\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    # Path to the new audio file for prediction\n",
        "    new_audio_file = \"/content/audio (2).wav\"\n",
        "\n",
        "    # Predict the speaker\n",
        "    predicted_speaker = predict_speaker(new_audio_file)\n",
        "\n",
        "    if predicted_speaker is not None:\n",
        "        print(\"Predicted Speaker:\", predicted_speaker)\n",
        "    else:\n",
        "        print(\"Unknown\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z9sgKTJLiRxv",
        "outputId": "fe54a757-6751-4a31-e66d-d23de399a211"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of new_features before scaling: (13,)\n",
            "Shape of trained_features_scaled: (2, 13)\n",
            "Shape of new_features_scaled: (1, 13)\n",
            "Similarity with speaker1 : 1\n",
            "Predicted Speaker: speaker1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pOCgFy-xiaPW"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}